
---
title: 'ANOVA etc.'
author: "Solutions"
output: word_document
fontsize: 12pt
---

Create a Word docx from this R Markdown file for the following exercise.  Submit the R markdown file and resulting Word docx file via D2L Dropbox.   

## Exercise 1

In the Lesson 3 presentation you saw how to use the Wilcoxon Rank Sum test to compare the difference in median repair times for Macs and PCs.  You'll find the `repair` dataset in the `DS705data` package.  In this problem we'll test the hypothesis that the population mean repair times are different for Macs and PCs at the 5% significance level using three different approaches.

$$ H_0: \mu_{\mbox{PC}} = \mu_{\mbox{Mac}}$$
$$H_a:  \mu_{\mbox{PC}} \neq \mu_{\mbox{Mac}} $$

### Part 1a

Even though repair times for both computer types are skewed right go ahead and use `t.test` to test if the population mean times are significantly different.  Include your R code below and write a conclusion to the test for practice.

### -|-|-|-|-|-|-|-|-|-|-|- Answer 1a -|-|-|-|-|-|-|-|-|-|-|-

```{r}
require(DS705data)
data(repair)
t.test.out = t.test(time~type,data=repair)
print(t.test.out)
```

Do not reject $H_0$ ($\alpha = 0.05, P = `r round(t.test.out$p.value,3)`).  There is not significant evidence to show the population mean repair times are different for PCs and Macs.  (We should be cautious here since the skewed distribution of times may make the t-test less accurate.)

---

### Part 1b

Now use the `boot` package to construct a 95% BCa confidence interval for the difference in population mean repair times.  Use at least 5000 resamples.  Use that confidence interval to write a hypothesis test conclusion to this hypothesis test.  (Review: you made similar bootstrap CI's in Lesson 3.)

### -|-|-|-|-|-|-|-|-|-|-|- Answer 1b -|-|-|-|-|-|-|-|-|-|-|-

```{r}
require(boot)
bootMeanDiff <- function(d,i){
  means <- tapply(d[i,1],d[,2],mean)
  means[1]-means[2]
}
boot.object <- boot(repair, bootMeanDiff, R = 5000, 
                    strata = repair$type)
bca.ci = boot.ci(boot.object,conf=.95,type='bca')$bca[4:5]
print(bca.ci)
```

We are 95% confident the population mean repair time for Macs is `r round(-bca.ci[2],2)` to `r round(-bca.ci[1],2)` hours less than the population mean repair time for PCs.

---

### Part 1c

Follow along with with Two Means example in the Bootstrap Hypothesis Testing presentation to bootstrap the two means t test to see if there is a significant difference in population mean repair times.  Include a histrogram of the boostrapped t-distribution and write a conclusion to the hypothesis test.  (NOTE: in the P value computation slide the last part got cut off, the full code is `P <- 2*min( sum( bootdist < toriginal), sum( bootdist > toriginal ) )/5000`.)

### -|-|-|-|-|-|-|-|-|-|-|- Answer 1c -|-|-|-|-|-|-|-|-|-|-|-

```{r}
Mac.idx = 1:62;
PC.idx = 63:122;
Mac.time = repair$time[Mac.idx]
PC.time = repair$time[PC.idx]
Mac.shift = Mac.time - mean( Mac.time )
PC.shift = PC.time - mean( PC.time )
set.seed(123) # for reproducibility
rs = rbind( replicate( 5000, sample(Mac.shift, replace = T) ),
            replicate( 5000, sample(PC.shift,  replace = T) ) )
bootdist <- apply(rs, 2, 
                  function(c) t.test(c[1:62],c[63:122])$statistic )
toriginal = t.test.out$statistic # from part 1a
P <- 2*min( sum( bootdist < toriginal), sum( bootdist > toriginal ) )/5000
print(P)
```

Reject $H_0$ ($\alpha = 0.05$, P = `r round(P,3)`).  There is significant evidence to show the population mean repair times are different for PCs and Macs.  

---

### Part 1d

The bootstrap and theoretical t-distributions give different results here.  Which do you trust?  Why?

### -|-|-|-|-|-|-|-|-|-|-|- Answer 1d -|-|-|-|-|-|-|-|-|-|-|-

```{r}
plot(density(bootdist))
df = t.test.out$parameter
x = seq(-4,5,by=.1)
y = dt(x,df)
lines(x,y,col='blue')
```
The black curve shown in the figure is the empirical density curve estimated from the bootstrap distribution.  It is very slightly skewed right which you can see in relation to the actual t-distribution shown in blue.  The original test statistic is `r round(toriginal,3)` in the left tail where the actual t-distribution is overestimating the p-value.  The bootstrap distribution better reflects the skewness of the original data and thus seems more trustworthy.
---

## Exercise 2

This exercise is based on the data and experimental design from exercises 8.42 & 8.43 in the Ott textbook.

A small corporation makes insulation shields for electrical wires using three different types of machines. The corporation wants to evaluate the variation in the inside diameter dimension of the shields produced by the machines. A quality engineer at the corporation randomly selects shields produced by each of the machines and records the inside diameters of each shield (in millimeters). The goal is to determine whether the location parameters (i.e. mean or median) of the three machines differ. The data set `shields` is in the `DS705data` package.  The R code to load it is already below.

### Part 2a

Construct side-by-side boxplots for the inside diameters of the insulation shields for the three machines.

### -|-|-|-|-|-|-|-|-|-|-|- Answer 2a -|-|-|-|-|-|-|-|-|-|-|-

```{r}
require(DS705data)
data(shields)
boxplot(Diameter~Machine,data=shields)
```

----

### Part 2b

Comment on what you see in the boxplots.  How do the medians compare visually?  Do the samples look like they have roughly the same variability?  Is there severe skewness or outliers in any of the samples?  Be specific.

### -|-|-|-|-|-|-|-|-|-|-|- Answer 2b -|-|-|-|-|-|-|-|-|-|-|-

Machines A and B seem to have similar median diameters, while Machine C seems to have a higher median diameter.  Sample A is fairly symmetric, sample B would be more or less symmetric except for one very large outlier, and sample C appears to be positively skewed.  Sample C shows much more variation (larger variance) than samples A and B whose variances might be similar.

----

### Part 2c

Which data conditions for ANOVA appear not to be met, if any?  Provide reasoning for your answer.

### -|-|-|-|-|-|-|-|-|-|-|- Answer 2c -|-|-|-|-|-|-|-|-|-|-|-

The populations do not have the same variance (they are heteroscedastic) and population C almost certainly isn't normally distributed.  Population A may be normally distributed.  Population B is also not likely to be normally distributed because it would be unlikely for a normal distribution to produce such a large outlier.

----

### Part 2d  

Conduct an analysis of variance test (the standard one that assumes normality and equal variance).  (i) State the null and alternative hypotheses, (ii) use R to compute the test statistic and p-value, and (iii) write a conclusion in context at $\alpha=0.05$.

### -|-|-|-|-|-|-|-|-|-|-|- Answer 2d -|-|-|-|-|-|-|-|-|-|-|-

(i)
$H_0: \mu_A = \mu_B = \mu_C$

$H_a:$ not all of the population mean diameters are the same.

(ii)
```{r}
l.model <- lm( Diameter ~ Machine, data = shields)
test <- anova(l.model)
test
P <- test$P[1]
```

(iii)
Do not reject $H_0$ at $\alpha = 0.05$ ($P$ = `r round(P,3)`).  There is not significant evidence to show that the population mean inside diameters are different.

----

### Part 2e

Conduct an analysis of variance test with the Welch correction.  (i) State the null and alternative hypotheses, (ii) use R to compute the test statistic and p-value, and (iii) write a conclusion in context at $\alpha=0.05$.

### -|-|-|-|-|-|-|-|-|-|-|- Answer 2e -|-|-|-|-|-|-|-|-|-|-|-

(i)
$H_0: \mu_A = \mu_B = \mu_C$

$H_a:$ not all of the population mean diameters are the same.

(ii)
```{r}
test <- oneway.test(Diameter ~ Machine, data = shields, var.equal=FALSE)
P <- test$p.value
```

(iii)
Do not reject $H_0$ at $\alpha = 0.05$ ($P$ = `r round(P,3)`).  There is not significant evidence to show that the population mean inside diameters are different.

----

### Part 2f

Which data conditions for Welch ANOVA are not met, if any?  Provide reasoning for your answer.

### -|-|-|-|-|-|-|-|-|-|-|- Answer 2f -|-|-|-|-|-|-|-|-|-|-|-

Population C almost certainly isn't normally distributed.  Population A may be normally distributed.  Population B is also not likely to be normally distributed because it would be unlikely for a normal distribution to produce such a large outlier.

----

### Part 2g
    
Conduct a Kruskal-Wallis test.  (i) State the null and alternative hypotheses, (ii) use R to compute the test statistic and p-value, and (iii) write a conclusion in context using $\alpha=0.05$.
    
### -|-|-|-|-|-|-|-|-|-|-|- Answer 2g -|-|-|-|-|-|-|-|-|-|-|-

(i)
$H_0:$ The populations have the same median

$H_1:$ The populations do not have the same median

(ii)
```{r}
test <- kruskal.test( Diameter ~ Machine, data = shields)
P <- test$p.value
```

(iii)
Reject $H_0$ at $\alpha = 0.05$ ($P$ = `r round(P,3)`).  There is significant evidence to show that the population median inside diameters are not all the same.

(We probably shouldn't be applying this as a test of medians since the boxplot suggests that the populations do not have the same shape and scale.)


----

### Part 2h

Which data conditions for the Kruskal-Wallis test are not met, if any?  Provide reasoning for your answer.

### -|-|-|-|-|-|-|-|-|-|-|- Answer 2h -|-|-|-|-|-|-|-|-|-|-|-

The distributions do not have the same shape.  Population C seems to be much more spread out than the others.

----

### Part 2i

Conduct a bootstrapped ANOVA test using pooled residuals and unequal variances as in the notes.  (i) State the null and alternative hypotheses, (ii) use R to compute the test statistic and p-value, and (iii) write a conclusion in context $\alpha=0.05$.  Do not use a helper function, instead mimic the code in the notes using a for loop to construct the boostrapped sampling distribution.

### -|-|-|-|-|-|-|-|-|-|-|- Answer 2i -|-|-|-|-|-|-|-|-|-|-|-

(i)
$H_0: \mu_A = \mu_B = \mu_C$ 

$H_a:$ not all the population means are the same.

(ii)
```{r cache=TRUE}
# Insert your R code here.
F.obs <- oneway.test( Diameter ~ Machine, data = shields, var.equal=FALSE)$statistic
F.obs
resA <- shields$Diameter[shields$Machine=='A'] - mean(shields$Diameter[shields$Machine=='A'])
resB <- shields$Diameter[shields$Machine=='B'] - mean(shields$Diameter[shields$Machine=='B'])
resC <- shields$Diameter[shields$Machine=='C'] - mean(shields$Diameter[shields$Machine=='C'])

B <- 10000; Fstar1 <- numeric(B)
for (i in 1:B){
  pop.null <- data.frame(res = sample( c(resA, resB, resC), replace = T), Machine=shields$Machine )
  Fstar1[i] <- oneway.test( res~Machine, data=pop.null, var.equal=FALSE)$statistic
}
# oneway.test will fail if any of the group standard deviations is zero, this can happen with resampling
Fstar1[ is.na( Fstar1 ) ] = 10*F.obs
p.approx1 <- sum( Fstar1 > F.obs )/B 
p.approx1
```

(iii)
Do not reject $H_0$ at $\alpha = 0.05$ ($P$ = `r round(p.approx1,3)`).  There is not significant evidence to show that the population mean inside diameters are different.

----

### Part 2j 

Repeat the bootstrapped ANOVA test using unpooled residuals and unequal variances as in the notes.  (i) State the null and alternative hypotheses, (ii) use R to compute the test statistic and p-value, and (iii) write a conclusion in context $\alpha=0.05$.  Go ahead and use the helper function or t1waybt do do this problem.

### -|-|-|-|-|-|-|-|-|-|-|- Answer 2j -|-|-|-|-|-|-|-|-|-|-|-

(i)
$H_0: \mu_A = \mu_B = \mu_C$ 

$H_a:$ not all the population means are the same.

(ii)
```{r}
source('anovaResampleFast.R')
out10<-anovaResampleFast(shields$Diameter,shields$Machine,B=10000,method=2,var.equal=F)
out10
```

(iii)
Do not reject $H_0$ at $\alpha = 0.05$ ($P$ = `r round(out10$p.boot,3)`).  There is not significant evidence to show that the population mean inside diameters are different.

----

### Part 2k

Which seems better and why, the bootstrap procedure with the pooled or unpooled residuals?

### -|-|-|-|-|-|-|-|-|-|-|- Answer 2k -|-|-|-|-|-|-|-|-|-|-|-

The three populations have different shapes and spreads, so it doesn't make sense to combine or pool the residuals into a single sample.  Unfortunately, since the samples are very small, there is limited information in the unpooled residuals and the bootstrap does not work very well.  We can never escape the need to have representative samples.

----

### Part 2l

Do any of the four statistical inference procedures used here provide a clear answer to the question of whether or not the three machines produce the same average inside diameter for the insulation shields?

### -|-|-|-|-|-|-|-|-|-|-|- Answer 2l -|-|-|-|-|-|-|-|-|-|-|-

Only one of the procedures, the Kruskal-Wallis test, gave a statistically significant result (at $\alpha = 0.05$) indicating that there might be different population centers.  However, the Kruskal-Wallis isn't really relevant here.  The ANOVA tests all require normality, but that doesn't seem reasonable for this problem either which casts into doubt the nearly significant result of the Welch ANOVA.  Bootstrapping with pooled residuals gave a nearly significant result, but pooling the residuals is suspect since the population variances seem quite different.  Boostrapping with unpooled residuals was not effective because of the very small sample sizes.  In short, none of these procedures give a clear answer.  But looking at the boxplot certainly suggests that machine C may have different inside diameters than machines A and B.

----

### Part 2m 

If you were responsible for conducting the statistical analysis here, what would you report to the engineer?

### -|-|-|-|-|-|-|-|-|-|-|- Answer 2m -|-|-|-|-|-|-|-|-|-|-|-

None of the statistical analyses gives reliable evidence to suggest the machines produce different inside wire diameters on average.

----

### Part 2n 

What impact do you think samples of sizes 5, 5, and 10 play here?

### -|-|-|-|-|-|-|-|-|-|-|- Answer 2n -|-|-|-|-|-|-|-|-|-|-|-

It is difficult to make a reliable inference with such little sample information.

----

### Part 2o

Often the Kruskall Wallis test is presented as a test of 

$H_0:$ the population distributions are all the same

$H_1:$ the population distributions are not all the same,

but this is not what KW tests as this example shows.  Take 3 random samples of size 100 from normal distributions having mean 0 and standard deviations 1, 10, and 50.  If KW were testing the hypotheses above, then we should reject $H_0$ since these three distributions are clearly different.  Run the KW test.  You should get a large $P$-value.  Why did you get a large $P$-value when the distributions are so different?

### -|-|-|-|-|-|-|-|-|-|-|- Answer 2o -|-|-|-|-|-|-|-|-|-|-|-

```{r echo = TRUE}
set.seed(321)
x <- c( rnorm(100,0,1), rnorm(100,0,10), rnorm(100,0,50))
groups <- factor( (rep( c('A','B','C'), each=100 ) ) )
d <- data.frame(x,groups)
kruskal.test( x ~ groups, data = d )
```

These distributions have different scale parameters (i.e. standard deviations) and are not identical in shape.


----
